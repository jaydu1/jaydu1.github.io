<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/en/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/en/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/en/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/en/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/en/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/en/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/en/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="jaydu1">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="jaydu1">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="jaydu1">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/en/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>jaydu1</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?edf6e323a1defe42b06a553cf51cfb67";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/en/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">jaydu1</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/en/" rel="section">
          
            
            
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/en/tags/" rel="section">
          
            
            
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/en/categories/" rel="section">
          
            
            
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/en/archives/" rel="section">
          
            
            
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-resources">
          <a href="/en/resources" rel="section">
          
            
            
            
              <i class="menu-item-icon fa fa-fw fa-download"></i> <br>
            
            Resources
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/en/../" rel="section">
          
            
            
            
              <i class="menu-item-icon fa fa-fw fa-language"></i> <br>
            
            中文
          </a>
        </li>
      

      
    </ul>
  

  
</nav>


 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/gre-sub-math/GreSubMathAdditionalTopics/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/gre-sub-math/GreSubMathAdditionalTopics/" itemprop="url">Chapter 7 - Additional Topics</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-03T12:00:00-06:00">
                2020-01-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/gre-sub-math/" itemprop="url" rel="index">
                    <span itemprop="name">gre-sub-math</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/gre-sub-math/GreSubMathAdditionalTopics/" class="leancloud_visitors" data-flag-title="Chapter 7 - Additional Topics">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Logic"><a href="#Logic" class="headerlink" title="Logic"></a>Logic</h1><h1 id="Set-Theory"><a href="#Set-Theory" class="headerlink" title="Set Theory"></a>Set Theory</h1><h1 id="Graph-Theory"><a href="#Graph-Theory" class="headerlink" title="Graph Theory"></a>Graph Theory</h1><h2 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h2><ul>
<li><p><strong>Definition</strong><br><em>A graph $G$ consists of a finite collection of vertices $V(G)$ and edges $E(G)$ where each edge connects a distinct pair of vertices.</em> </p>
<ul>
<li>We only discuss the <em>undirected graph</em>, which is the <em>simple graph</em> (at most one edge between any two vertices) and its edges have no orientation.</li>
<li>The <em>order</em> of $G$ is $|V|$ and the <em>size</em> of $G$ is $|E|$. </li>
<li>Two vertices are <em>adjacent vertices</em>  if they are connected by a edge. </li>
<li>The <em>degree</em> of a vertice is the number of adjacent vertices of it. A vertex with an odd (even) degree is an odd (even) vertice.</li>
<li>A graph is <em>complete</em> if every distinct pair of vertices is connected by an edge.</li>
</ul>
</li>
<li><p><strong>Properties</strong></p>
<ul>
<li>Graphs $F$ and $G$ are <em>isomorphic</em> if there exists a function $f:V(F)\rightarrow V(G)$ that is both one-to-one and onto, and all adjacencies are preserved.</li>
</ul>
</li>
</ul>
<h2 id="Path-Cycle-Forest-and-Tree"><a href="#Path-Cycle-Forest-and-Tree" class="headerlink" title="Path, Cycle, Forest and Tree"></a>Path, Cycle, Forest and Tree</h2><p>A <em>path</em> is a sequence of adjacent vertices and the connecting edges. A graph is <em>connected</em> if every pair of vertices can be connected by at least one path. A path that begins and ends at the same vertex is a <em>cycle</em>. A graph with no cycles is a <em>forest</em>, and if such a graph is connected, it is a <em>tree</em>.</p>
<h2 id="Subgraph-Spanning-Graph-And-Spanning-Tree"><a href="#Subgraph-Spanning-Graph-And-Spanning-Tree" class="headerlink" title="Subgraph, Spanning Graph And Spanning Tree"></a>Subgraph, Spanning Graph And Spanning Tree</h2><p>Let $G$ be a graph with vertex and edge sets $V(G)$ and $E(G)$. $H$ is a subgraph of $G$ if</p>
<ol>
<li>$V( H) \subseteq V(G)$;</li>
<li>$E(H)\subseteq E(H)$;</li>
<li>every edge of $H$ connects two vertices of $H$,<br>which means that the vertices of $H$ are a subset of the vertices of $G$, and every pair of adjacent vertices in $H$ also appears in $G$.</li>
</ol>
<p>Furthermore, if $V(H)=V(G)$, then $H$ is a <em>spanning subgraph</em> of $G$. In addition, if $H$ is a tree, then $H$ is a <em>spanning tree</em> of $G$.</p>
<h1 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h1><h1 id="Combinatorics"><a href="#Combinatorics" class="headerlink" title="Combinatorics"></a>Combinatorics</h1><h1 id="Probability-And-Statistics"><a href="#Probability-And-Statistics" class="headerlink" title="Probability And Statistics"></a>Probability And Statistics</h1><h1 id="Point-Set-Topology"><a href="#Point-Set-Topology" class="headerlink" title="Point-Set Topology"></a>Point-Set Topology</h1><h2 id="Continuous-Functions"><a href="#Continuous-Functions" class="headerlink" title="Continuous Functions"></a>Continuous Functions</h2><h3 id="Continuous-Functions-between-Topological-Spaces"><a href="#Continuous-Functions-between-Topological-Spaces" class="headerlink" title="Continuous Functions between Topological Spaces"></a>Continuous Functions between Topological Spaces</h3><h3 id="Open-Maps"><a href="#Open-Maps" class="headerlink" title="Open Maps"></a>Open Maps</h3><ul>
<li><strong>Definition</strong><br><em>A map $f:X_1\rightarrow X_2$ is open if the image of every open set in $X_1$ is open in $X_2$.</em></li>
</ul>
<h3 id="Homeomorphisms"><a href="#Homeomorphisms" class="headerlink" title="Homeomorphisms"></a>Homeomorphisms</h3><ul>
<li><strong>Definition</strong><br><em>If a map $f:X_1\rightarrow X_2$ is a bijection, and both $f$ and $f^{-1}$ are continuous (or equivalently, $f$ is a continuous and open map), then $f$ is a homeomorphism.</em></li>
</ul>
<p>Homeomorphism is similar to isomorphism between groups or rings, in the sense that it preserves topological structure including the cardinal number of topology, connectedness and compactness.</p>
<ul>
<li><strong>Properties</strong><ul>
<li><em>Let $f:X_1\rightarrow X_2$ be a bijective, continuous map of topological spaces. If $X_1$ is compact and $X_2$ is Huasdorff, then $f$ is a homeomorphism.</em></li>
</ul>
</li>
</ul>
<h2 id="Connectedness"><a href="#Connectedness" class="headerlink" title="Connectedness"></a>Connectedness</h2><h2 id="Compactness"><a href="#Compactness" class="headerlink" title="Compactness"></a>Compactness</h2><h2 id="Metric-Spaces"><a href="#Metric-Spaces" class="headerlink" title="Metric Spaces"></a>Metric Spaces</h2><h1 id="Real-Analysis"><a href="#Real-Analysis" class="headerlink" title="Real Analysis"></a>Real Analysis</h1><h1 id="Complex-Variables"><a href="#Complex-Variables" class="headerlink" title="Complex Variables"></a>Complex Variables</h1><h2 id="Complex-Numbers"><a href="#Complex-Numbers" class="headerlink" title="Complex Numbers"></a>Complex Numbers</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Thre <em>complex numbers</em> $\mathbb{C}$ is a set of all order pairs of real numbers $(x,y)$. The <em>imaginary unit</em> $i$ is a complex number such that $i^2=-1$. Then each complex number can be expressed as $z=x+yi$ where $x\in\mathbb{R}$ and $y\in\mathbb{R}$  are called the <em>real part</em> and <em>imaginary part</em> of $z$, denoted by $\text{Re} z$ and $\text{Im} z$ respectively. The <em>(complex) conjugate</em> of $z$ is the number $\overline{z}=x-yi$.</p>
<p>The complex numbers can be graphed on the <em>complex plane</em> ($xy$-plane). The horizontal $x$-axis is called the <em>real axis</em> and the vertical $y$-axis is called the <em>imaginary axis</em>.</p>
<p>The <em>modulus</em>, <em>magnitude</em> or <em>absolute value</em> of $z$ is given by $|z|=\sqrt{x^2+y^2}$. The absolute value of $z$ satisfies $|z|^2=z\overline{z}$.</p>
<h3 id="The-Polar-Form"><a href="#The-Polar-Form" class="headerlink" title="The Polar Form"></a>The Polar Form</h3><p>The angle $\theta$ that the vector (from the origin to $z$) makes with the positive real axis is called an <em>argument</em> of $z$, denoted by $\text{arg} z$. We can add any integer multiple of $2n\pi$ to an argument of $z$, and the result is another argument of $z$. Therefore, we define the <em>principal argument</em> of $z$, denoted by $\text{Arg} z$ as the unique value of the argument that lies in the interval $-\pi&lt;\theta\leq \pi$.</p>
<p>Let $r=|z|$, $x=r\cos\theta$ and $y=r\sin\theta$, then the polar form of $z$ is given by</p>
<script type="math/tex; mode=display">z=r(\cos\theta+i\sin\theta).</script><h3 id="The-Exponential-Form"><a href="#The-Exponential-Form" class="headerlink" title="The Exponential Form"></a>The Exponential Form</h3><p>From the <em>Euler’s Formula</em> <script type="math/tex">e^{i\theta}=\cos\theta+i\sin\theta,</script><br>the exponential form of $z$ is given by <script type="math/tex">z=re^{i\theta}.</script><br>A useful result that follows from Euler’s Formula is <script type="math/tex">(\cos\theta+i\sin\theta)^n=\cos(n\theta)+i\sin(n\theta).</script></p>
<h2 id="Complex-Functions"><a href="#Complex-Functions" class="headerlink" title="Complex Functions"></a>Complex Functions</h2><h3 id="Complex-Roots"><a href="#Complex-Roots" class="headerlink" title="Complex Roots"></a>Complex Roots</h3><p>If $n$ is a positive number, we can solve the equation $z^n=1$ and the solutions are called <em>$n^{\text{th}}$ roots of unity</em>. The equation can be expressed as $r^ne^{in\theta}=e^{i2k\pi}$ for $k\in \mathbb{Z}$. So $r=1$, $\theta= \frac{2k\pi}{n}$ and $z=e^{i\frac{2k\pi}{n}}$ for $k=0,1,\ldots,n-1$.</p>
<p>More generally, if we want to solve the equation $z^n=w$, or equivalently, $r^ne^{i\theta}=Re^{i(\Theta+2k\pi)}$ for $k\in\mathbb{Z}$. Then the solution is given by $R^{\frac{1}{n}}e^{i\frac{\Theta+2k\pi}{n}}$ for $k=0,1,\ldots,n-1$.</p>
<h3 id="Complex-Logarithms"><a href="#Complex-Logarithms" class="headerlink" title="Complex Logarithms"></a>Complex Logarithms</h3><p>If we write $z=re^{i(\theta+2k\pi)}$ for $k\in\mathbb{Z}$, then the logarithms of $z$ is given by $\log z=\log r+i(\theta+2k\pi)$. The principal logarithm of $z$ is gievn by $\\text{Log}z=\log|z|+i\text{Arg}z.$</p>
<h3 id="Complex-Powers"><a href="#Complex-Powers" class="headerlink" title="Complex Powers"></a>Complex Powers</h3><p>For complex numbers $z$ and $w$, the complex power is given by $z^w=e^{w\log z}$ and the principal value of $z^w$ is equal to $z^w=e^{w\text{Log} z}$.</p>
<h3 id="The-Trigonometric-Functions"><a href="#The-Trigonometric-Functions" class="headerlink" title="The Trigonometric Functions"></a>The Trigonometric Functions</h3><p>The cosine and sine of a complex number are defined as </p>
<script type="math/tex; mode=display">\cos z=\frac{e^{iz}+e^{-iz}}{2}\qquad \sin z=\frac{e^{iz}-e^{-iz}}{2i}.</script><h3 id="The-Hyperbolic-Functions"><a href="#The-Hyperbolic-Functions" class="headerlink" title="The Hyperbolic Functions"></a>The Hyperbolic Functions</h3><p>The hyperbolic cosin and the hyperbolic sine are defined as </p>
<script type="math/tex; mode=display">\cosh z=\frac{e^z+e^{-z}}{2}\qquad \sinh z=\frac{e^{z}-e^{-z}}{2}.</script><h2 id="Differentiability-of-Complex-Functions"><a href="#Differentiability-of-Complex-Functions" class="headerlink" title="Differentiability of Complex Functions"></a>Differentiability of Complex Functions</h2><h3 id="The-Derivative-of-A-Function-of-A-Complex-Variable"><a href="#The-Derivative-of-A-Function-of-A-Complex-Variable" class="headerlink" title="The Derivative of A Function of A Complex Variable"></a>The Derivative of A Function of A Complex Variable</h3><p>The function $f$ can be expressed as $f(z)=f(x+yi)=u(x,y)+iv(x,y)$. A function $f(z)$ is said to be <em>differentiable</em> at the point $z_0$ if $\lim\limits_{z\rightarrow z_0}\frac{f(z)-f(z_0)}{z-z_0}$ exists. The nonzero complex number $z$ can approach the origin from infinitely many directions, which is a very strong condition.</p>
<h3 id="The-Cauchy-Riemann-Equations"><a href="#The-Cauchy-Riemann-Equations" class="headerlink" title="The Cauchy-Riemann Equations"></a>The Cauchy-Riemann Equations</h3><p>If $f$ is differentiable at $z_0$, then the limit <script type="math/tex">\lim\limits_{z\rightarrow z_0}\frac{f(z)-f(z_0)}{z-z_0}=\lim\limits_{z\rightarrow z_0}\frac{u(x,y)-u(x_0,y_0)}{z-z_0}+\lim\limits_{z\rightarrow z_0}i\frac{v(x,y)-v(x_0,y_0)}{z-z_0}</script> exists. If we let $z$ approach the origin along the real axis, then <script type="math/tex">\lim\limits_{z\rightarrow z_0}\frac{f(z)-f(z_0)}{z-z_0}=\frac{\partial u}{\partial x}+i\frac{\partial v}{\partial x}.</script> If we let $z$ approach the origin along the imaginary axis, then <script type="math/tex">\lim\limits_{z\rightarrow z_0}\frac{f(z)-f(z_0)}{z-z_0}=\frac{1}{i}\frac{\partial u}{\partial y}+\frac{\partial v}{\partial y}=\frac{\partial v}{\partial y}-i\frac{\partial u}{\partial y}.</script><br>Therefore, <script type="math/tex">\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y}\qquad \frac{\partial v}{\partial x}=-\frac{\partial u}{\partial y},</script> which is called the <em>Cauchy-Riemann equations</em>. Conversely, if the Cauchy-Riemann equations are satisfied and the four partial derivatives are continuous throughout an open set containing $z_0$, then the function $f$ is differentiable at the point $z_0$.</p>
<h3 id="Analytic-Functions"><a href="#Analytic-Functions" class="headerlink" title="Analytic Functions"></a>Analytic Functions</h3><p>If $f(z)$ is differentiable at $z_0$ and at every point throughout some open set in the complex plane containing $z_0$, then we say that $f(z)$ is <em>analytic</em> at the point $z_0$. In general, if $f(z)$ is differentiable throughout some open set $O$ in the complex plane, then $f(z)$ is said to be analytic in $O$. If $f(z)$ is analytic everywhere in the complex plane, then $f(z)$ is said to be an <em>entire function</em>.</p>
<h3 id="Singularities-And-Poles"><a href="#Singularities-And-Poles" class="headerlink" title="Singularities And Poles"></a>Singularities And Poles</h3><ul>
<li>If a function $f(z)$ is not analytic at $z_0$, but is analytic at some point in every punctured disk center at $z_0$, then $z_0$ is said to be a <em>singularity</em> of $f(z)$. </li>
<li>If $z_0$ is a singularity of $f(z)$ and $f(z)$ is analytic at every point in some puctured open disk centered at $z_0$, then we call $z_0$ an <em>isolated singularity</em>. If there is a positive number $n$ such that $f(z)=\frac{g(z)}{(z-z_0)^n}$ with $g(z)$ analytic in a nonpunctured open disk centered at $z_0$ and $g(z_0)\neq 0$, then the isolated singularity $z_0$ of $f$ is called a <em>pole of order $n$</em>. Otherwise, $z_0$ is called an <em>essential singularity</em> if we canot write $f(z)$ in this form for any positive number $n$.</li>
<li><em>Nonisolated singularities</em> can be cluster points or natural boundaries.</li>
</ul>
<h2 id="Complex-Line-Integrals"><a href="#Complex-Line-Integrals" class="headerlink" title="Complex Line Integrals"></a>Complex Line Integrals</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>Let $C$ be a smooth path in the complex plane, which is given parametrically by the equation $z(t) = x(t) + iy(t)$, from $t = a$ to $t = b$ (where $t$ is real). If $f(z )$ is a continuous function along $C$, then we have: <script type="math/tex">\int_C f(z)\mathrm{d}z=\int_a^b f(z(t))\cdot z'(t)\mathrm{d}t.</script><br>Alternatively, we could have invoked the fundamental theorem of calculus abd written <script type="math/tex">\int_Cf(z)\mathrm{d}z=F(z(b))-F(z(a)),</script>where $F(z)$ is an antiderivative of $f( z )$.</p>
<h3 id="Complex-Line-Integrals-of-Analytic-Functions"><a href="#Complex-Line-Integrals-of-Analytic-Functions" class="headerlink" title="Complex Line Integrals of Analytic Functions"></a>Complex Line Integrals of Analytic Functions</h3><ul>
<li><em>Cauchy’s Theorem</em>: If $f(z)$ is analytic throughout a simply connected, open set $O$, then for every closed path $C$ in $O$, we have:<script type="math/tex">\oint_C f(z）\mathrm{d}z=0.</script> In particular, if $f(z)$ is an entire function, then $\oint_C f(z）\mathrm{d}z=0$ for any closed path in the plane.</li>
<li><em>Morera’s Theorem</em>: If $f(z)$ is continuous throughout an open, connected set $O$ in the complex plane, and $\oint_C f(z)\mathrm{d}z = 0$ for every closed curve $C$ in $O$, then $f (z)$ is analytic in $O$.</li>
<li><em>Cauchy’s Integral Formulas</em>: If $f(z)$ is analytic at all points within and on a simple, closed path, $C$, that surrounds the point $z_0$, then:<script type="math/tex">f(z_0)=\frac{1}{2\pi i}\oint_C\frac{f(z)}{z-z_0}\mathrm{d}z.</script> Furthermore, the $n$th derivative, $f^{(n)}(z)$, is also analytic at $z_0$ for all positive integers $n$, and:<script type="math/tex">f^{(n)}(z_0)=\frac{1}{2\pi i}\oint_C\frac{f(z)}{(z-z_0)^{n+1}}\mathrm{d}z.</script></li>
</ul>
<h3 id="The-Residue-Theorem"><a href="#The-Residue-Theorem" class="headerlink" title="The Residue Theorem"></a>The Residue Theorem</h3><p>If $z_0$ is the only singularity in a connected open set $O$, and $C\in O$ is a simple, closed, positively oriented curve in the annulus where the Laurent series expansion of $f(z)$ is valid, then <script type="math/tex">a_{-1}=\frac{1}{2\pi i}\oint_Cf(z)\mathrm{d}z.</script><br>The number $a_{-1}$, which is the coefficient of $(z-z_0)^{-1}$ in the Laurent series of $$f(z)$, called the <em>residue</em> of $f(z)$ at the singularity $z_0$, denoted by $\text{Res}(z_0,f)$. </p>
<p>Furthermore, if $z_0$ is a pole of order $k$, then <script type="math/tex">\text{Res}(z_0,f)=\frac{1}{k!}\lim\limits_{z\rightarrow z_0}\frac{\mathrm{d^{k-1}}}{\mathrm{d}z^{k-1}}[(z-z_0)^kf(z)].</script></p>
<p>If the curve $C$ surrounds more than one singularity of $f(z)$, the <em>residue theorem</em> says that if $f(z)$ is analytic throughout the interior of $C$, except at a finite number of singularity $z_1,\ldots,z_n$ inside $C$, then <script type="math/tex">\oint_Cf(z)\mathrm{d}z=2\pi i\cdot\sum\limits_{i=1}^n\text{Res}(z_n,f).</script></p>
<h2 id="Series-Expansion"><a href="#Series-Expansion" class="headerlink" title="Series Expansion"></a>Series Expansion</h2><h3 id="Taylor-Series"><a href="#Taylor-Series" class="headerlink" title="Taylor Series"></a>Taylor Series</h3><h3 id="Laurent-Series"><a href="#Laurent-Series" class="headerlink" title="Laurent Series"></a>Laurent Series</h3><p>If $f(z)$ is analytic in an annulus $R_1&lt;|z-z_0|&lt;R_2$ where $R_1\in[0,\infty)$, $R_2\in(0,\infty]$ and $R_1&lt;R_2$, then it can be expanded in a <em>Laurent series</em>,</p>
<script type="math/tex; mode=display">f(z)=\underbrace{\sum\limits_{n=1}^{\infty}a_{-n}(z-z_0)^{-n}}_{\text{singular part}}+\underbrace{\sum\limits_{n=0}^{\infty}a_{n}(z-z_0)^{n}}_{\text{analytic part}}.</script><p>The coefficients can be calculated as</p>
<script type="math/tex; mode=display">a_n=\frac{f^{(n)}(z_0)}{n!}</script><script type="math/tex; mode=display">a_{-n}=\frac{1}{2\pi i}\oint\frac{f(z)}{(z-z_0)^{-n+1}}\mathrm{d}z</script><p>for $n\geq0$.</p>
<p>In practice, we don’t usually figure out the Laurent coefficients from this formula; instead, we derive them by algebraic manipulations of the Taylor series.</p>
<h1 id="Numerical-Analysis"><a href="#Numerical-Analysis" class="headerlink" title="Numerical Analysis"></a>Numerical Analysis</h1>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/gre-sub-math/GreSubMathAbstractAlgebra/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/gre-sub-math/GreSubMathAbstractAlgebra/" itemprop="url">Chapter 6 - Number Theory and Abstract Algebra</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-03T11:00:00-06:00">
                2020-01-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/gre-sub-math/" itemprop="url" rel="index">
                    <span itemprop="name">gre-sub-math</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/gre-sub-math/GreSubMathAbstractAlgebra/" class="leancloud_visitors" data-flag-title="Chapter 6 - Number Theory and Abstract Algebra">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Number-Theory"><a href="#Number-Theory" class="headerlink" title="Number Theory"></a>Number Theory</h1><h2 id="Divisibility"><a href="#Divisibility" class="headerlink" title="Divisibility"></a>Divisibility</h2><h3 id="The-Euclidean-Algorithm"><a href="#The-Euclidean-Algorithm" class="headerlink" title="The Euclidean Algorithm"></a>The Euclidean Algorithm</h3><h3 id="The-Diophantine-Equation"><a href="#The-Diophantine-Equation" class="headerlink" title="The Diophantine Equation"></a>The Diophantine Equation</h3><h2 id="Congruences"><a href="#Congruences" class="headerlink" title="Congruences"></a>Congruences</h2><p>Let $a,$, $b$ and $n$ be integers. If $n\neq 0$, we say that $a$ is congruent to $b$ modulo $n$ if $a-b$ is divisible by $n$, which is written $a\equiv b(\text{mod}\  n)$. </p>
<ul>
<li>If $a\equiv b(\text{mod}\  n)$ and $b\equiv c(\text{mod}\  n)$, then $a\equiv c(\text{mod}\  n)$.</li>
<li>If $a\equiv b(\text{mod}\  n)$, then for any $c$, $a\pm c\equiv b\pm c(\text{mod}\  n)$ and $ac\equiv bc(\text{mod}\  n)$.</li>
<li>If $a_1\equiv b_1(\text{mod}\  n)$ and $a_2\equiv b_2(\text{mod}\  n)$, then $a_1\pm a_2\equiv b_1\pm b_2(\text{mod}\  n)$ and <script type="math/tex">a_1a_2\equiv b_1b_2(\text{mod}\  n)</script>.</li>
<li>For any positive integer $c$, the statement $a\equiv b(\text{mod}\  n)$ is equivalent to the congruences $a\equiv b,b+n,\ldots,b+(c-1)n\ (\text{mod}\  n)$.</li>
<li>If $ab\equiv ac(\text{mod}\  n)$, then $b\equiv c(\text{mod}\  n)$ if $\text{gcd}(a,n)=1$ or $b\equiv c(\text{mod}\  \frac{n}{d})$ if $d=\text{gcd}(a,n)&gt;1$.</li>
<li><strong>Fermat’s Little Theorem.</strong> If $p$ is a prime and $a$ is an integer, then $a^p\equiv a(\text{mod}\  p)$ for any $a$, and $a^{p-1}\equiv 1(\text{mod}\  p)$ if $o$ does not divide $a$.</li>
</ul>
<h1 id="Abstract-Algebra"><a href="#Abstract-Algebra" class="headerlink" title="Abstract Algebra"></a>Abstract Algebra</h1><h2 id="Groups"><a href="#Groups" class="headerlink" title="Groups"></a>Groups</h2><p>Let $S$ be a nonempty set, then a <em>binary operation</em> on $S$ is a function $f:S\times S\rightarrow S$ (closed under the binary operation). $f(a,b)$ is usually denoted by $a<em>b$ for $a,b\in S$. A nonempty set $S$, together with a binary operation defined on it, is called a </em>binary structure*.</p>
<p>A binary structure whose binary operation is <em>associative</em>, i.e., <script type="math/tex">(a*b)*c=a*(b*c)</script> is called a <em>semigroup</em>.</p>
<p>The element $e$ of $S$ with the property that <script type="math/tex">a*e=e*a=a,</script> for every $a\in S$ is called the <em>identity</em>. The identity may not exist for some binary structures. A semigroup that has an identity is called a <em>monoid</em>.</p>
<p>Let $(S,<em>)$ be a monoid, if $\forall\ a\in S$, $\exists\ a^{-1}\in S$ being the inverse of $a$, such that <script type="math/tex">aa^{-1}=a^{-1}a=e,</script><br>then $(S,</em>)$ is a <em>group</em>. </p>
<p>A semigroup, monoid, or group whose binary operation is <em>commutative</em>, i.e. <script type="math/tex">a*b=b*a,</script> is said <em>Abelian</em>.</p>
<p><strong>Common notations.</strong> We usually just write $ab$, instead of $a * b$, even if the operation isn’t ordinary multiplication. Also, if the binary operation is commutative, it’s common to see it denoted by $+$, even if the operation isn’t ordinary addition.</p>
<p>A group $G$ with the property that there’s an element $a$ in $G$ such that <script type="math/tex">G=\{a^n:n=0,1,2,\ldots\}</script><br>is said to be <em>cyclic</em>, and the element $a$ is a <em>generator</em> of the group.</p>
<ul>
<li>The integer $m$ is a generator of $(\mathbb{Z}_n,\oplus)$ if and only if $m$ is relatively prime to $n$.</li>
<li>Let $G$ be a cyclic group with generator $a$. The element $a^m$ is a generator of $G$ if and only if $m$ is relatively prime to $n$.</li>
</ul>
<p>If a pair of groups are <em>isomorphic</em>, then all their structural properties are identical.</p>
<h2 id="Subgroup"><a href="#Subgroup" class="headerlink" title="Subgroup"></a>Subgroup</h2><p>Let $(G, <em> )$ be a group. If there’s a subset $H$ of $G$ such that $(H, </em>)$ is also a group, then we say that $H$ is a <em>subgroup</em> of $G$, and write $H \leq G$. If $H\neq G$, then $H$ is a <em>proper subgroup</em> of $G$, denoted by $H&lt;G$. The <em>trivial subgroups</em> of $G$ are $\{e\}$ and $G$.</p>
<p>The <em>cyclic subgroup</em> generated by $a\in G$ is given by $\langle a\rangle=\{a^n:n\in\mathbb{Z}\}$. The order of an element of a group is the order of $\langle a\rangle$.</p>
<p>For some groups, particularly large ones, it’s often more economical to specify a set of generators and a set of equations connecting them-called <em>relations</em>-that can be used to reconstruct the entire group table. Together, the set of generators and set of relations is called a <em>presentation</em> of the group.</p>
<ul>
<li><strong>Lagrange’s Theorem.</strong> Let $G$ be a finite group. If $H$ is a subgroup of $G$, then the order of $H$ divides the order of $G$.</li>
<li>Let $G$ be a finite, Abelian group of order $n$. Then $G$ has at least one subgroup of order $d$ for every (positive) divisor $d$ of $n$.</li>
<li>Let $G$ be a finite, cyclic group of order $n$. Then $G$ has exactly one subgroup-a cyclic subgroup-of order $d$ for every (positive) divisor $d$ of $n$. If $G$ is generated by $a$, then the subgroup generated by the element $b=a^m$ has order $d = \frac{n}{\text{gcd}(m, n )}$. [If $m = 0$, then we’ll agree that $\text{gcd}(m, n) = n$.]</li>
<li><strong>Cauchy’s Theorem.</strong> Let $G$ be a finite group of order $n$, and let $p$ be a prime that divides $n$. Then $G$ has at least one subgroup of order $p$.</li>
<li><strong>Sylow’s First Theorem.</strong> Let $G$ be a finite group of order $n=p^km$, where $p$ is a prime that does not divide $m$.Then $G$ has at least one subgroup of order $p^i$ for every integer $i$ from $0$ to $k$.</li>
</ul>
<h2 id="Group-Homomorphisms"><a href="#Group-Homomorphisms" class="headerlink" title="Group Homomorphisms"></a>Group Homomorphisms</h2><p>Let $(G,\cdot)$ and $(G’,<em>)$ be groups. A function $\phi:G\rightarrow G’$ with the property that $$\phi(a\cdot b)=\phi(a)</em>\phi(b)$$<br>for all elements $a$ and $b$ in $G$, is called a group <em>homomorphism</em>.</p>
<ul>
<li>If $e$ is the identity in $G$, then $\phi(e)$ is the identity in $G’$.</li>
<li>If $g\in G$ has finite order $m$, then $\phi(g)\in G’$ also has order $m$.</li>
<li>If $a^{-1}$ is the inverse of $a$ in $G$, then $\phi(a^{-1 })$ is the inverse of $\phi(a)$ in $G’$.</li>
<li>If $H$ is a subgroup of $G$, then $\phi(H)$ is a subgroup of $G’$, where $\phi(H)=\{\phi(h):h\in H\}$.</li>
<li>If $G$ is finite, then the order of $\phi(G)$ divides the order of $G$; if $G’$ is finite, then the order of $\phi(G)$ also divides the order of $G’$.</li>
<li>If $H’$ is a subgroup of $G’$, then $\phi^{-1} (H’)$ is a subgroup of $G$, where $\phi^{-1}(H’)=\{h\in G:\phi(h)\in H’\}$.</li>
</ul>
<p>A homomorphism that’s one-to-one (injective) is called a <em>monomorphism</em>; if it’s onto (surjective), it’s called an <em>epimorphism</em>; and if it’s one-to-one and onto (bijective), it’s called an <em>isomorphism</em>. A homomorphism from a group to itself is called an <em>endomorphism</em>, and an isomorphism from a group to itself is called an <em>automorphism</em>.</p>
<ul>
<li>A homomorphism is a monomorphism if and only if its kernel $\text{ker}\phi=\{g\in G:\phi(g)=e’\}$ is trivial.</li>
<li>The kernel of a group homomorphism $\phi: G\rightarrow G’$ is always a subgroup of $G$.</li>
</ul>
<h2 id="Direct-Product-And-Direct-Sum"><a href="#Direct-Product-And-Direct-Sum" class="headerlink" title="Direct Product And Direct Sum"></a>Direct Product And Direct Sum</h2><p>The <em>direct product</em> of the groups $(G_1,<em>_1)$ and $(G_2,</em>_2)$ is  the group $(G_1\times G_2,<em>)$ where <script type="math/tex">G_1\times G_2=\{(a,b):a\in G_1,b\in G_2\}</script> and $</em>$ is the defined binary operation such that <script type="math/tex">(a_1,a_2)*(b_1,b_2)=(a_1*_1 b_1,a_2*_2 b_2).</script></p>
<p>For Abelian groups, we use the notation $G_1\oplus G_2$ and call it as <em>direct sum</em>.</p>
<ul>
<li>The direct sum $\mathbb{Z}_m\oplus \mathbb{Z}_n$ is cyclic if and only if $\text{gcd}(m, n) = 1$. If this is the case, then, $\mathbb{Z}_m\oplus \mathbb{Z}_n$ is isomorphic to $\mathbb{Z}_{mn}$.</li>
<li>The direct sum $\mathbb{Z}_{m_1}\oplus \cdots \oplus\mathbb{Z}_{m_k}$ is cyclic if and only if $\text{gcd}(m_i , m_j) = 1$ for every distinct pair $m_i$ and $m_j$. If this is the case, then $\mathbb{Z}_{m_1}\oplus \cdots \oplus\mathbb{Z}_{m_k}$ is isomorphic to $\mathbb{Z}_{m_1m_2\cdots m_k}.$</li>
<li>Every finite Abelian group $G$ is isomorphic to a direct sum of the form <script type="math/tex">\mathbb{Z}_{p_1^{k_1}}\oplus\cdots\oplus \mathbb{Z}_{p_r^{k_r}}</script> where the $p_i$ are (not necessarily distinct) primes and $k$ are (not necessarily distinct) positive integers. The collection of prime powers $p_i^{k_i}$ for a given representation of $G$, are known as the <em>elementary divisors</em> of $G$.</li>
<li>Every finite Abelian group G is isomorphic to a direct sum of the form <script type="math/tex">\mathbb{Z}_{m_1}\oplus\cdots\oplus \mathbb{Z}_{m_t}</script> where $m_1\geq 2$, $m_{i-1}$ divides $m_{i}$ for $i=1,\ldots,t.$ The distinct list $m_1,\cdots,m_t$ is called the <em>invariant factors</em> of $G$.</li>
</ul>
<h2 id="Rings"><a href="#Rings" class="headerlink" title="Rings"></a>Rings</h2><p>A set $R$, together with two binary operations (we’ll use addition, $+$, and multiplication, $\cdot$), is called a <em>ring</em> if the following conditions are satisfied:</p>
<ol>
<li>$(R,+)$ is a Abelian group;</li>
<li>$(R,\cdot)$ is a semigroup;</li>
<li>the distributive laws hold; that is, for every $a$, $b$, and $c$ in $R$, we have:<script type="math/tex">a*(b+c)=a*b+a*c\qquad (a+d)*c=a*c+d*c.</script></li>
</ol>
<p>The smallest positive integer $n$ such that $na = 0$ for every $a$ in R (if such an $n$ exists) is called the <em>characteristic</em> of the ring, and we write $\text{char} R = n$.</p>
<p>If the multiplicative semigroup $(R, \cdot )$ is a monoid-that is, if there’s a multiplicative identity-then $R$ is called a <em>ring with unity</em>. The identity of the additive abelian group $(R, +)$ is usually denoted by $0$ and, in a ring with unity, the identity of the multiplicative monoid $(R, \cdot )$ is usually denoted by 1.</p>
<p>If the operation of multiplication is commutative, then we call $R$ a commutative ring. (The term abelian is generally not used to describe a ring in which multiplication is commutative.)</p>
<p>If $S$ is a subset of $R$, and $S$ satisfies the ring requirements with the same operations as $R$, then we say that $(S, +, \cdot )$ is a subring of $(R, +, \cdot)$.</p>
<ul>
<li><strong>ring of polynomial.</strong> The ring of polynomials with coefficients in a ring $R$ is usually denoted by $R[x_1,\cdots,x_n]$ or $R[x]$ where $x$ refer to the set of variables $\{x_1,\cdots,x_n\}$. An element $f(x)\in \mathbb{R}[x]$ can be written as a finite sum <script type="math/tex">f(x)=\sum\limits_b b_{\alpha} x^{\alpha},</script><br>where $\alpha=(\alpha_1,\cdots,\alpha_d)$ is a multi-index and $\alpha_i\in \mathbb{R}$.</li>
</ul>
<h2 id="Ring-Homomorphisms"><a href="#Ring-Homomorphisms" class="headerlink" title="Ring Homomorphisms"></a>Ring Homomorphisms</h2><p>Let $(R, +, \times)$ and $(R’, \oplus,\otimes)$ be rings. A function $\phi: R \rightarrow R’$ is called a <em>ring homomorphism</em> if both of the following conditions hold for be every $a$ and $b$ in $R$:</p>
<ol>
<li>$\phi(a+b)=\phi(a)\oplus\phi(b).$</li>
<li>$\phi(a\times b)=\phi(a)\otimes\phi(b).$</li>
</ol>
<ul>
<li>The kernel of a ring homomorphism is the set $\text{ker}\phi=\{a \in R : \phi(a) = 0’\}$, where $0’ $ is the additive identity in $R’$ and is always a subring of $R$.</li>
<li>The image of $R$, $\phi(R)=\{\phi(r):r\in R\}$ is a subring of $R’$.</li>
<li>The image of $0$, the additive identity in $R$, must be $0’$.</li>
</ul>
<!--## Ideal
An *ideal*  $I$ of a ring $R$ is a nonempty subset of $R$ with there properties:
<dd>(a) $I$ is closed under addition;<br> (b) If $s\in I$ and $r\in R$, then $rs\in I$. Thus, $0\in I$.
</dd>-->
<p>A commutative ring with unity ($1\neq 0$) that contains no zero divisors is called an <em>integral domain</em>. The <em>cancellation law</em> holds for integral domains.</p>
<h2 id="Fields"><a href="#Fields" class="headerlink" title="Fields"></a>Fields</h2><p>Let $a$ be a nonzero element of a ring $R$ with unity. If $a$ is invertible, then $a$ is called a <em>unit</em>. If every nonzero element in $R$ is a unit, i.e. $(R^<em>,\cdot)$ is a group, then $R$ is called a </em>divison ring<em>. A commutative division ring is called a </em>field*.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/gre-sub-math/GreSubMathCalculusII/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/gre-sub-math/GreSubMathCalculusII/" itemprop="url">Chapter 3 - Calculus II</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-01-03T10:00:00-06:00">
                2020-01-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/gre-sub-math/" itemprop="url" rel="index">
                    <span itemprop="name">gre-sub-math</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/gre-sub-math/GreSubMathCalculusII/" class="leancloud_visitors" data-flag-title="Chapter 3 - Calculus II">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Analytic-Geometry-Of-mathbb-R-3"><a href="#Analytic-Geometry-Of-mathbb-R-3" class="headerlink" title="Analytic Geometry Of $\mathbb{R}^3$"></a>Analytic Geometry Of $\mathbb{R}^3$</h1><h2 id="Vector-Products"><a href="#Vector-Products" class="headerlink" title="Vector Products"></a>Vector Products</h2><h3 id="The-Dot-Product"><a href="#The-Dot-Product" class="headerlink" title="The Dot Product"></a>The Dot Product</h3><p>The <em>dot product</em> is give by</p>
<script type="math/tex; mode=display">A\cdot B=|A||B|\cos\theta</script><p>where $\theta$ is the angle between $A$ and $B$.</p>
<h3 id="The-Cross-Product"><a href="#The-Cross-Product" class="headerlink" title="The Cross Product"></a>The Cross Product</h3><p>The <em>corss product</em> $A\times B$ is the vector that’s perpendicular by right-hand rule to the plane containing $A$ and $B$ and whose magnitude is $|A||B|\sin\theta$.</p>
<p>$|A\times B|$ is the area of the parallelogram formed by $A$ and $B$.</p>
<p>Also, we have <script type="math/tex">A\times B=\left|\begin{matrix}i & j & k\\
a_1&a_2&a_3\\
b_1&b_2&b_3\end{matrix}\right|,</script><br>where $i,j,k$ are the standard coordinate unit basis.</p>
<h3 id="The-Triple-Scalar-Product"><a href="#The-Triple-Scalar-Product" class="headerlink" title="The Triple Scalar Product"></a>The Triple Scalar Product</h3><p>The <em>triple scalar product</em> is $(A\times B)\cdot C$. $|(A\times B)\cdot B|$ is the volume of parallelepiped formed by $A$, $B$ and $C$. Also, <script type="math/tex">(A\times B)\cdot C=\left|\begin{matrix}
a_1&a_2&a_3\\
b_1&b_2&b_3\\
c_1&c_2&c_3\end{matrix}\right|.</script></p>
<h2 id="Geometry"><a href="#Geometry" class="headerlink" title="Geometry"></a>Geometry</h2><h3 id="Lines"><a href="#Lines" class="headerlink" title="Lines"></a>Lines</h3><p>The distance $d$ from a point $({ x }_{ 0 },{ y }_{ 0 })$ to the line $Ax+By+C=0$ is given by <script type="math/tex">d=\frac{|Ax_0+Bx_0+C|}{\sqrt{A^2+B^2}}.</script></p>
<h3 id="Planes"><a href="#Planes" class="headerlink" title="Planes"></a>Planes</h3><p>The nearest point to the origin in the plane $Ax+By+Cz=D$ is given by <script type="math/tex">\left(\frac{AD}{A^2+B^2+C^2},\frac{BD}{A^2+B^2+C^2},\frac{CD}{A^2+B^2+C^2}\right),</script><br>and the distance $d$ from the origin to this plane is given by <script type="math/tex">d=\frac{\sqrt{(AD)^2+(BD)^2+(CD)^2}}NaN,</script></p>
<h3 id="The-Tangent-Plane-To-A-Surface"><a href="#The-Tangent-Plane-To-A-Surface" class="headerlink" title="The Tangent Plane To A Surface"></a>The Tangent Plane To A Surface</h3><p>The equation of the tangent plane to the surface $z=f(x,y)$ at $P=(x_0,y_0,z_0)$ is <script type="math/tex">z-z_0=f_x|_P\cdot (x-x_0)+f_y|_P\cdot (y-y_0).</script></p>
<h3 id="Cylinders"><a href="#Cylinders" class="headerlink" title="Cylinders"></a>Cylinders</h3><h3 id="Surfaces-Of-Revolution"><a href="#Surfaces-Of-Revolution" class="headerlink" title="Surfaces Of Revolution"></a>Surfaces Of Revolution</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Curve</th>
<th>Axis Revolved Around</th>
<th>Replace</th>
<th>By</th>
<th>Surface of Revolution</th>
</tr>
</thead>
<tbody>
<tr>
<td>$f(x,y)=0$</td>
<td>$x$</td>
<td>$y$</td>
<td>$\pm\sqrt{y^2+z^2}$</td>
<td>$f(x,\pm\sqrt{y^2+z^2})=0$</td>
</tr>
<tr>
<td>$f(x,y)=0$</td>
<td>$y$</td>
<td>$x$</td>
<td>$\pm\sqrt{x^2+z^2}$</td>
<td>$f(\pm\sqrt{x^2+z^2},y)=0$</td>
</tr>
</tbody>
</table>
</div>
<p>And other cases are similar by replace $x$ or $y$ by $z$.</p>
<h3 id="Levle-Curves-And-Level-Surfaces"><a href="#Levle-Curves-And-Level-Surfaces" class="headerlink" title="Levle Curves And Level Surfaces"></a>Levle Curves And Level Surfaces</h3><p>For function $z=f(x,y)$, the level curve of height $c$ is given by $f(x,y)=c$.</p>
<h2 id="Coordinates"><a href="#Coordinates" class="headerlink" title="Coordinates"></a>Coordinates</h2><h3 id="Cylindrical-Coordinates"><a href="#Cylindrical-Coordinates" class="headerlink" title="Cylindrical Coordinates"></a>Cylindrical Coordinates</h3><p>The cylindrical coordinates are given by $(r,\theta,z)$ where $r=\sqrt{x^2+y^2}$ and $\theta=\arctan\frac{y}{x}$.</p>
<h3 id="Spherical-Coordinates"><a href="#Spherical-Coordinates" class="headerlink" title="Spherical Coordinates"></a>Spherical Coordinates</h3><p>The spherical coordinates are given by $(\rho,\phi,\theta)$ where $\rho=\sqrt{x^2+y^2+z^2}$, $\theta=\arctan\frac{y}{x}$ and $\phi=\arctan\frac{\sqrt{x^2+y^2}}{z}$.</p>
<h1 id="Derivatives"><a href="#Derivatives" class="headerlink" title="Derivatives"></a>Derivatives</h1><h2 id="Partial-Derivatives"><a href="#Partial-Derivatives" class="headerlink" title="Partial Derivatives"></a>Partial Derivatives</h2><h2 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h2><p>Consider the surface $z = f(x, y)$, and let $P = (x_0, y_0)$ be a point in the domain of $f$. The <em>gradient</em> of $f$ is the vector $\nabla f=\left(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\right)$.</p>
<h2 id="Directional-Derivatives"><a href="#Directional-Derivatives" class="headerlink" title="Directional Derivatives"></a>Directional Derivatives</h2><p>The rate of change of $f$ at the point $P$ in the direction of a unit vector $\mathbf{u}$, is given by $D_{\mathbf{u}}f|_P=\nabla f|_P\cdot \mathbf{u}.$</p>
<p>The vector $\nabla f$ points in the direction in which $f$ increases most rapidly, and the magnitude of $\nabla f$ gives the maximum rate of increase.</p>
<p>For a function $f (x, y, z)$, the vector $\nabla f|_P$ is perpendicular (normal) to the level curve off that contains $P$.</p>
<p>Similar definitions and results can be given for $\mathbb{R}^3$.</p>
<h1 id="Max-Min-Problems"><a href="#Max-Min-Problems" class="headerlink" title="Max/Min Problems"></a>Max/Min Problems</h1><p>$P_0$ is a critical point of $f(x,y)$ if $\frac{\partial f}{\partial x}\big|_{P_0}=\frac{\partial f}{\partial y}\big|_{P_0}=0.$ </p>
<p>Let $\Delta= \text{det}(H)$. </p>
<p>If $\Delta&gt;0$ and $f_{xx}(P_0)&lt;0$, then $f$ attains a local maximum at $P_0$.</p>
<p>If $\Delta&gt;0$ and $f_{xx}(P_0)&gt;0$, then $f$ attains a local minimum at $P_0$.</p>
<p>If $\Delta&lt;0$, then $f$ has a saddle point at $P_0$.</p>
<p>If $\Delta=0$, then no conclusion can be drawn.</p>
<h1 id="Integrals"><a href="#Integrals" class="headerlink" title="Integrals"></a>Integrals</h1><h2 id="Line-Integrals"><a href="#Line-Integrals" class="headerlink" title="Line Integrals"></a>Line Integrals</h2><h3 id="Line-Integrals-With-Respect-To-Arc-Length"><a href="#Line-Integrals-With-Respect-To-Arc-Length" class="headerlink" title="Line Integrals With Respect To Arc Length"></a>Line Integrals With Respect To Arc Length</h3><h4 id="Curve"><a href="#Curve" class="headerlink" title="Curve"></a>Curve</h4><p>Consider a function $f(x,y)$ and a curve $C$ in the $xy$-plane. A curve given parametrically by the vector equation $\mathbf{r}=r(t)=(x(t),y(t))$ is said to be <em>smooth</em>, if $r’(t)$ is continuous and nonzero. And it is <em>piecewise smooth</em> if it is composed of a finite number of smooth curves joined at consecutive endpoints.</p>
<h4 id="Line-Integrals-In-mathbb-R-2"><a href="#Line-Integrals-In-mathbb-R-2" class="headerlink" title="Line Integrals In $\mathbb{R}^2$"></a>Line Integrals In $\mathbb{R}^2$</h4><p>If $C$ is an oriented, piecewise smooth curve, we partition $C$ into $n$ segments with arc length $\Delta s_i$ and choose $P_i=(x_i,y_i)$ in each segment. Then the <em>line integral of $f$ along $C$ with respect to arc length</em> is defined as <script type="math/tex">\int_C f\mathrm{d}s=\lim\limits_{n \rightarrow\infty}f(x_i,y_i)\Delta s_i,</script><br>where $\mathrm{d}s=\sqrt{(\mathrm{d}x)^2+(\mathrm{d}y)^2}$.</p>
<p>In parametric form, <script type="math/tex">\int_C f\mathrm{d}s=\pm\int_a^b f(x(t),y(t)) \sqrt{[x'(t)]^2+[y'(t)]^2}\mathrm{d}t,</script><br>where the sign depends on the parameter $t$. If $t$ increases in the positive direction on $C$, then we use the $+$ sign and otherwise we use the $-$ sign.</p>
<p>If $C$ is a closed curve, we usually use the notation $\oint_C$ to replace $\int_C$.</p>
<h4 id="Line-Integrals-In-mathbb-R-3"><a href="#Line-Integrals-In-mathbb-R-3" class="headerlink" title="Line Integrals In $\mathbb{R}^3$"></a>Line Integrals In $\mathbb{R}^3$</h4><p>Analogously, we have </p>
<script type="math/tex; mode=display">\int_C f\mathrm{d}s=\pm\int_a^b f(x(t),y(t),z(t)) \sqrt{[x'(t)]^2+[y'(t)]^2+[z'(t)]^2}\mathrm{d}t.</script><h3 id="The-Line-Integrals-Of-A-Vector-Field"><a href="#The-Line-Integrals-Of-A-Vector-Field" class="headerlink" title="The Line Integrals Of A Vector Field"></a>The Line Integrals Of A Vector Field</h3><h4 id="Vector-Field"><a href="#Vector-Field" class="headerlink" title="Vector Field"></a>Vector Field</h4><p>Let $D$ be a region of the plane on which a pair of continuous functions, $M(x, y)$ and $N(x, y)$, are both defined. Then the function $\mathbf{F}=F(x,y)=(M(x,y),N(x,y))$ in $D$ is a continuous <em>vector field</em> on $D$. </p>
<h4 id="The-Line-Integrals-Of-A-Vector-Field-In-mathbb-R-2"><a href="#The-Line-Integrals-Of-A-Vector-Field-In-mathbb-R-2" class="headerlink" title="The Line Integrals Of A Vector Field In $\mathbb{R}^2$"></a>The Line Integrals Of A Vector Field In $\mathbb{R}^2$</h4><p>Let $r(t)=(x(t),y(t))$ be a parameterization of the curve $C$. Then the <em>line integral of the vector field $F$ along $C$</em> is defined as: <script type="math/tex">\int_C \mathbf{F}\cdot \mathrm{d} \mathbf{r}=\int_a^b \mathbf{F}(\mathbf{r}(t))\cdot \mathbf{r}'(t)\mathrm{d}t=\int_CM\mathrm{d}x+N\mathrm{d}y.</script></p>
<h4 id="Fundamental-Theorem"><a href="#Fundamental-Theorem" class="headerlink" title="Fundamental Theorem"></a>Fundamental Theorem</h4><p>The function $F(x,y)$ is a <em>gradient field</em> if there is a scalar field $f$ such that $F=\nabla f$. $f$ is called a <em>potential</em> of $F$.</p>
<p>If $C$ is any piecewise smooth curve oriented from the initial point $A$ to the final point $B$, and $f$ is a continuously differentiable function defined on $C$, then: <script type="math/tex">\int_C\nabla f\cdot \mathrm{d}\mathbf{r}=f(B)-f(A).</script></p>
<p>If $F$ is a gradient field, then $F$ is <em>conservative</em>, that is the integral of the vector field depends only on the initial and final points of $C$. Therefore, $\oint_C \mathbf{F}\cdot\mathrm{d}\mathbf{r}=0$ for any closed curve $C$, if and only if $F$ is a gradient field.</p>
<h2 id="Double-Integrals"><a href="#Double-Integrals" class="headerlink" title="Double Integrals"></a>Double Integrals</h2><h2 id="Green’s-Theorem"><a href="#Green’s-Theorem" class="headerlink" title="Green’s Theorem"></a>Green’s Theorem</h2><p>A <em>simple closed curve</em> is one that doesn’t cross itself between its endpoints. The <em>positive direction</em> of the closed curve is defined as the direction you would have to walk in order to keep the region enclosed by the curve on your _left_.</p>
<p>Consider a simple closed curve $C$ enclosing a region $D$, so that $C$ is the boundary of $D$. If $M(x,y<br>)$ and $N(x,y)$ are functions that has coontinuous partial derivatives both on $C$ and throughout $D$, then <em>Green’s theorem</em> says that:<script type="math/tex">\oint_CM\mathrm{d}x+N\mathrm{d}y=\iint_{D}\left(\frac{\partial N}{\partial x}-\frac{\partial M}{\partial y}\right)\mathrm{d}x\mathrm{d}y.</script></p>
<p>It connects line integrals with double integrals in the region bounded by the line.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/machine-learning/IntroductionOfMachineLearning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/machine-learning/IntroductionOfMachineLearning/" itemprop="url">Introduction of Machine Learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-21T19:00:00-05:00">
                2019-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/machine-learning/IntroductionOfMachineLearning/" class="leancloud_visitors" data-flag-title="Introduction of Machine Learning">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="What-is-machine-learning"><a href="#What-is-machine-learning" class="headerlink" title="What is machine learning?"></a>What is machine learning?</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><ul>
<li>Literlly, “machine” denotes “programming computer” and “learning” denotes “learn from data”.</li>
<li>In a general sense, machine learning means that the computer can learn some ability without explicitly programming.</li>
<li>From the perspective of engineering, given some task $T$, corresponding experience (training data) $E$ and performance measurement $P$, machine learning hopes to learn from $E$ so that the performance $P$ on task $T$ can be improved.</li>
</ul>
<img src="/en/machine-learning/IntroductionOfMachineLearning/overview.png" title="Overview">
<p>Machine learning is a interdisciplinary field, which relates to computer science, statistics, mathematics and so on.</p>
<h2 id="Basic-element"><a href="#Basic-element" class="headerlink" title="Basic element"></a>Basic element</h2><ul>
<li>Data. Every insatcne is called <strong>sample</strong>. The set of training and testing data is called <strong>training set</strong> and <strong>testing set</strong>, respectively. Since for some algorithms, parameters are required to be tuned, we need to split a subset from the training set, which is called <strong>evaluation set</strong> and used for determining how good or bad the parameters are.</li>
<li>Model. It can be viewed as a function $f$. Given an input $x$, one can get an output $y$. The model may rely on some changeable parameters $\theta$. The process of learning is to update $\theta$.</li>
<li>Performance measurement. It is used to evalute the performance of the model. We can use <strong>utility function</strong>, <strong>fitness function</strong> to evaluate how good a model is. And we can also use the <strong>cost function</strong> to evaluate how bad a model is.</li>
</ul>
<h2 id="Procedure"><a href="#Procedure" class="headerlink" title="Procedure"></a>Procedure</h2><ul>
<li>To study data;</li>
<li>To select a model;</li>
<li>To train the model on the training set;</li>
<li>To make a(n) prediction/inference on new data.</li>
</ul>
<h1 id="Why-use-machine-learnig"><a href="#Why-use-machine-learnig" class="headerlink" title="Why use machine learnig?"></a>Why use machine learnig?</h1><ul>
<li>To do work that requires a lot of hand-tuning or long lists of rules;</li>
</ul>
<img src="/en/machine-learning/IntroductionOfMachineLearning/1.png" title="Traditional approach">
<img src="/en/machine-learning/IntroductionOfMachineLearning/2.png" title="Machine learning approach">
<ul>
<li>To adpat to change of environment/data;</li>
</ul>
<img src="/en/machine-learning/IntroductionOfMachineLearning/3.png" title="Adaptive machine learning approach">
<ul>
<li>To solve problems that is difficult for human;</li>
<li>To learning unkonwn rules (<em>data mining</em>)</li>
</ul>
<img src="/en/machine-learning/IntroductionOfMachineLearning/4.png" title="Helping humen to learn">
<h1 id="Types-of-machine-learning"><a href="#Types-of-machine-learning" class="headerlink" title="Types of machine learning"></a>Types of machine learning</h1><p>There are many categories for machine learning algorithms. Generally, we can classify them from the following perspectives.</p>
<h2 id="Training-data"><a href="#Training-data" class="headerlink" title="Training data"></a>Training data</h2><h3 id="Supervised-learning"><a href="#Supervised-learning" class="headerlink" title="Supervised learning."></a>Supervised learning.</h3><p>In supervised learning, each training sample $x\in \mathscr{X}$ has a label $y\in\mathscr{Y}$.</p>
<ul>
<li>Classification. The label set $\mathscr{Y}$ consists of finite elements, such as $\{0,1\}$, $\{\text{Yes}, \text{No}\}$ and so on. The classification task is to determine which class is for a given sample.</li>
</ul>
<img src="/en/machine-learning/IntroductionOfMachineLearning/5.png" title="Classification">
<ul>
<li>Regression. The label set $\mathscr{Y}$ consists of an interval or even more complex elements, such as $[0,1]$. The regression task is to find a suitable map from $\mathscr{X}$ to $\mathscr{Y}$.</li>
</ul>
<img src="/en/machine-learning/IntroductionOfMachineLearning/6.png" title="Regression">
<ul>
<li>Ranking. The samples are splitted into different group, and the label set can either be discrete or continuous. This is a special task and commonly used in recommended systems. It aims to give ranks of samples in a group.</li>
</ul>
<p>Some common supervised learning algorithms are given below:</p>
<ul>
<li>k-Nearest Neighbors</li>
<li>Linear Regression</li>
<li>Logistic Regression</li>
<li>Support Vector Machines (SVMs)</li>
<li>Decision Trees and Random Forests</li>
<li>Neural networks</li>
</ul>
<h3 id="Unsupervised-learning"><a href="#Unsupervised-learning" class="headerlink" title="Unsupervised learning."></a>Unsupervised learning.</h3><ul>
<li>Clustering<ul>
<li>K-Means </li>
<li>DBSCAN </li>
<li>Hierarchical Cluster Analysis (HCA)</li>
</ul>
</li>
<li>Anomaly detection and novelty detection<ul>
<li>One-class SVM </li>
<li>Isolation Forest</li>
</ul>
</li>
<li>Visualization and dimensionality reduction<ul>
<li>Principal Component Analysis (PCA)</li>
<li>Kernel PCA</li>
<li>Locally-Linear Embedding (LLE)</li>
<li>t-distributed Stochastic Neighbor Embedding (t-SNE)    </li>
</ul>
</li>
<li>Association rule learning<ul>
<li>Apriori</li>
<li>Eclat</li>
</ul>
</li>
</ul>
<h3 id="Semisupervised-learning"><a href="#Semisupervised-learning" class="headerlink" title="Semisupervised learning."></a>Semisupervised learning.</h3><h3 id="Reinforcement-learning"><a href="#Reinforcement-learning" class="headerlink" title="Reinforcement learning."></a>Reinforcement learning.</h3><a href="/en/reinforcement-learning/IntroductionOfReinforcementLearning/" title="Introduction Of Reinforcement Learning">Introduction Of Reinforcement Learning</a>
<h2 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h2><ul>
<li>Offline learning/batch learning.</li>
<li>Online learning.</li>
</ul>
<h2 id="Generalizing"><a href="#Generalizing" class="headerlink" title="Generalizing"></a>Generalizing</h2><ul>
<li>Instance-based learning.</li>
<li>Model-based learning.</li>
</ul>
<h1 id="Main-challenges-of-machine-learning"><a href="#Main-challenges-of-machine-learning" class="headerlink" title="Main challenges of machine learning"></a>Main challenges of machine learning</h1><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><ul>
<li>Lack of training data;</li>
<li>Lack of representitive of training data;</li>
<li>Poor quaility of training data;</li>
<li>Irrelevant features.</li>
</ul>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><ul>
<li>Overfitting of models on training data;</li>
<li>Underfitting of models on training data.</li>
</ul>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" target="_blank" rel="noopener">Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/reinforcement-learning/IntroductionOfReinforcementLearning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/reinforcement-learning/IntroductionOfReinforcementLearning/" itemprop="url">Introduction Of Reinforcement Learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-07T10:20:54-05:00">
                2019-05-07
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/reinforcement-learning/" itemprop="url" rel="index">
                    <span itemprop="name">reinforcement-learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/reinforcement-learning/IntroductionOfReinforcementLearning/" class="leancloud_visitors" data-flag-title="Introduction Of Reinforcement Learning">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Reinforcement learning is a computational goal-directed approach to learning from interaction with environment.</p>
<img src="/en/reinforcement-learning/IntroductionOfReinforcementLearning/rl.png" title="Reinforcement Learning">
<ul>
<li>trial-and-error search </li>
<li>delayed reward</li>
</ul>
<p>We can use ideas from dynamical systems theory to formulate a reinforcement learning problem, specifically, as the optimal control of incompletely-known Markov decision processes. A learning agent must be able to sense the state of its environment to some extent and must be able to take actions that affect the state. The agent also must have a goal or goals relating to the state of the environment.</p>
<p>One of the challenges that arise in reinforcement learning, and not in other kinds of learning, is the trade-off between <strong>exploration</strong> and <strong>exploitation</strong>. The agent has to exploit what it has already experienced in order to obtain reward, but it also has to explore in order to make better action selections in the future.</p>
<p>Methods based on general principles, such as search or learning, were characterized as “weak methods,” whereas those based on speciﬁc knowledge were called “strong methods.”</p>
<h1 id="Taxonomy"><a href="#Taxonomy" class="headerlink" title="Taxonomy"></a>Taxonomy</h1><p>In reinforcement learning, we have two orthogonal choices: what kind of objective to optimize (involving a policy, value function, or dynamics model), and what kind of function approximators to use.</p>
<p>First, we have two kinds of algorithms:</p>
<ul>
<li>Model-based RL algorithms: based on dynamics model that tends to predict the next state and the reward at the next step;</li>
<li>Model-free RL algorithms: not based on a dynamics model.</li>
</ul>
<p>Then, for model-free RL algorithms, the figure below shows a taxonomy:</p>
<img src="/en/reinforcement-learning/IntroductionOfReinforcementLearning/rl_category.png" title="A Taxonomy of Model-free RL Algorithms">
<p>Policy optimization methods are centered around the policy, the function that maps the agent’s state to its next action. These methods view reinforcement learning as a numerical optimization problem where we optimize the expected reward with respect to the policy’s parameters. There are two ways to optimize a policy. </p>
<ol>
<li>Derivative free optimization (DFO) algorithms, including evolutionary algorithms, like genetic programming, simulated annealing, etc.;</li>
<li>Policy gradient methods.</li>
</ol>
<p>Approximate dynamic programming (ADP) focus on learning value functions, which predict how much reward the agent is going to receive.</p>
<p>Finally, there are actor-critic methods that combine elements from both policy optimization and dynamic programming. These methods optimize a policy, but they use value functions to speed up this optimization, and often use ideas from approximate dynamic programming to fit the value functions.</p>
<h1 id="Elements-of-Reinforcement-Learning"><a href="#Elements-of-Reinforcement-Learning" class="headerlink" title="Elements of Reinforcement Learning"></a>Elements of Reinforcement Learning</h1><ul>
<li>a policy;</li>
<li>a reward signal;</li>
<li>a value function;</li>
<li>(optionally) a model of the environment.</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/reinforcement-learning/POMDP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/reinforcement-learning/POMDP/" itemprop="url">Partially Observable Markov Decision Process</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-07T10:20:54-05:00">
                2019-05-07
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/reinforcement-learning/" itemprop="url" rel="index">
                    <span itemprop="name">reinforcement-learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/reinforcement-learning/POMDP/" class="leancloud_visitors" data-flag-title="Partially Observable Markov Decision Process">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h1><p>A discrete-time partially observable Markov decision process (POMDP) models the relationship between an agent and its environment. Formally, a POMDP is a 7-tuple $(S,A,T,R,\Omega,O,\gamma)$, where </p>
<ul>
<li>$S$ is a set of states; </li>
<li>$A$ is a set of actions; </li>
<li>$T$ is a set of conditional transition probabilities between states;</li>
<li>$R: S \times A \to \mathbb{R}$ is the reward function;</li>
<li>$\Omega$ is a set of observations,</li>
<li>$O$ is a set of conditional observation probabilities;</li>
<li>$\gamma \in [0, 1]$ is the discount factor.</li>
</ul>
<p>At each time period, the environment is in some state $s\in S$. The agent takes an action $a\in A$, which causes the environment to transition to state $s’$ with probability $T(s’|s,a)$. At the same time, the agent receives an observation $o\in \Omega$ which depends on the new state of the environment, $s’$, and on the just taken action, $a$, with probability $O(o|s’,a)$. Finally, the agent receives a reward $r$ equal to $R(s, a)$. Then the process repeats. The goal is for the agent to choose actions at each time step that maximize its expected future discounted reward: $\mathbb{E}\left[\sum_{t=0}^{\infty}{\gamma}^tr_t\right]$, where $r_t$ is the reward earned at time $t$. The discount factor $\gamma$ determines how much immediate rewards are favored over more distant rewards. </p>
<p>When $\gamma =0$ the agent only cares about which action will yield the largest expected immediate reward; when $\gamma =1$ the agent cares about maximizing the expected sum of future rewards.</p>
<script type="math/tex; mode=display">\begin{align*}
\text{Underlying Model}\qquad&s_0\rightarrow s_1\rightarrow \cdots \qquad\qquad\\
&\downarrow\ \ \ \ \downarrow  \qquad\qquad\\ 
\text{Observation}\qquad &o_0\rightarrow o_1\rightarrow \cdots \qquad\qquad\\ 
&\downarrow\ \ \ \ \downarrow  \qquad\qquad\\ 
\text{Belief}\qquad&b_0\rightarrow b_1\rightarrow \cdots \qquad\qquad
\end{align*}</script><h1 id="Belief-MDP"><a href="#Belief-MDP" class="headerlink" title="Belief MDP"></a>Belief MDP</h1><p>The belief $b(s)$ of the agent is a function describing the probability of being in state $s$ at one moment. After having taken the action $a$ and observing $o$, an agent needs to update its belief in the state the environment may (or not) be in. Since the state is Markovian (by assumption), maintaining a belief over the states solely requires knowledge of the previous belief state, the action taken, and the current observation. The operation is denoted $b’ = \tau(b,a,o)$. Below we describe how this belief update is computed.</p>
<p>After reaching $s’$, the agent observes $o\in \Omega$  with probability $O(o\mid s’,a)$. Let $b$ be a probability distribution over the state space $S$. $b(s)$ denotes the probability that the environment is in state $s$. Given $b(s)$, then after taking action $a$ and observing $o$,</p>
<script type="math/tex; mode=display">b'(s')=\eta O(o\mid s',a)\sum_{s\in S}T(s'\mid s,a)b(s)</script><p>where $\eta =\frac{1}{\mathbb{P}(o\mid b,a)}$ is a normalizing constant with $\mathbb{P}(o\mid b,a)=\sum _{s’\in S}O(o\mid s’,a)\sum_{s\in S}T(s’\mid s,a)b(s)$.</p>
<p>A Markovian belief state allows a POMDP to be formulated as a Markov decision process where every belief is a state. The resulting belief MDP will thus be defined on a continuous state space (even if the “originating” POMDP has a finite number of states: there are infinite belief states (in $B$) because there are an infinite number of mixtures of the originating states (of $S$)), since there are infinite beliefs for any given POMDP.</p>
<p>Formally, the belief MDP is defined as a tuple $(B,A,\tau,r,\gamma)$ where</p>
<ul>
<li>$B$ is the set of belief states over the POMDP states;</li>
<li>$A$ is the same finite set of action as for the original POMDP;</li>
<li>$\tau$  is the belief state transition function;</li>
<li>$r:B \times A \to \mathbb{R}$ is the reward function on belief states;</li>
<li>$\gamma$  is the discount factor equal to the $\gamma$  in the original POMDP.</li>
</ul>
<p>Of these, $\tau$ and $r$ need to be derived from the original POMDP. $\tau$ is</p>
<script type="math/tex; mode=display">\tau(b,a,b') = \sum_{o\in \Omega} \mathbb{P}(b'|b,a,o) \mathbb{P}(o | a, b),</script><p>where $\mathbb{P}(o|a,b)$ is the value derived in the previous section and</p>
<script type="math/tex; mode=display">\mathbb{P}(b'|b,a,o)=\begin{cases}
1&\text{if the belief update with arguments }b,a,o\text{ returns }b'\\
0&\text{otherwise }
\end{cases}.</script><p>The belief MDP reward function ($r$) is the expected reward from the POMDP reward function over the belief state distribution:</p>
<script type="math/tex; mode=display">r(b,a) = \sum_{s\in S} b(s) R(s,a).</script><p>The belief MDP is not partially observable anymore, since at any given time the agent knows its belief, and by extension the state of the belief MDP.</p>
<h1 id="Policy-And-Value-Function"><a href="#Policy-And-Value-Function" class="headerlink" title="Policy And Value Function"></a>Policy And Value Function</h1><p>Unlike the “originating” POMDP (where each action is available from only one state), in the corresponding Belief MDP all belief states allow all actions, since you (almost) always have some probability of believing you are in any (originating) state. As such, $\pi$  specifies an action $a=\pi(b)$ for any belief $b$.</p>
<p>Here it is assumed the objective is to maximize the expected total discounted reward over an infinite horizon. When $R$ defines a cost, the objective becomes the minimization of the expected cost.</p>
<p>The expected reward for policy $\pi$ starting from belief $b_{0}$ is defined as</p>
<script type="math/tex; mode=display">V^\pi(b_0) = \sum_{t=0}^\infty  \gamma^t r(b_t, a_t) = \sum_{t=0}^\infty \gamma^t \mathbb{E}\Bigl[ R(s_t,a_t) \mid b_0, \pi \Bigr]</script><p>where $\gamma&lt;1$ is the discount factor. The optimal policy $\pi^\ast$ is obtained by optimizing the long-term reward.</p>
<script type="math/tex; mode=display">\pi ^{\ast}=\underset  {\pi }{\mbox{argmax}}\ V^{\pi }(b_{0})</script><p>where $b_{0}$ is the initial belief.</p>
<p>The optimal policy, denoted by $\pi^\ast$, yields the highest expected reward value for each belief state, compactly represented by the optimal value function $V^{\ast}$. This value function is solution to the Bellman optimality equation:</p>
<script type="math/tex; mode=display">V^{\ast}(b)=\max_{a\in A}\Bigl[ r(b,a)+\gamma \sum _{o\in \Omega }\mathbb{P}(o\mid b,a)V^{\ast}(\tau (b,a,o))\Bigr]</script><p>For finite-horizon POMDPs, the optimal value function is piecewise-linear and convex. It can be represented as a finite set of vectors. In the infinite-horizon formulation, a finite vector set can approximate $V^{\ast}$ arbitrarily closely, whose shape remains convex. Value iteration applies dynamic programming update to gradually improve on the value until convergence to an $\epsilon$-optimal value function, and preserves its piecewise linearity and convexity. By improving the value, the policy is implicitly improved. Another dynamic programming technique called policy iteration explicitly represents and improves the policy instead. These are the same as value iteration and policy iteration MDP.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/reinforcement-learning/MDP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/reinforcement-learning/MDP/" itemprop="url">Markov Decision Process</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-05T21:39:54-05:00">
                2019-05-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/reinforcement-learning/" itemprop="url" rel="index">
                    <span itemprop="name">reinforcement-learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/reinforcement-learning/MDP/" class="leancloud_visitors" data-flag-title="Markov Decision Process">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Markov-Decision-Process"><a href="#Markov-Decision-Process" class="headerlink" title="Markov Decision Process"></a>Markov Decision Process</h1><p>A Markov decision process is a $5$-tuple $(S,A,P_{\cdot}(\cdot,\cdot),R_{\cdot}(\cdot,\cdot),\gamma)$, where</p>
<ul>
<li><p>$S$ is a finite set of states.</p>
</li>
<li><p>$A$ is a finite set of actions (alternatively, $A(s)$ is the finite set of actions available from state $s$).</p>
</li>
<li><p>$R_{a}(s,s’)$ is the immediate reward (or expected immediate reward) received after transitioning from state $s$ to state $s’$, due to $a$. It can also be like $R(s)$ or $R(s,a)$.</p>
</li>
<li><p>$P_a(s,s’)=P(s_{t+1}=s’|s_t=s,a_t=a)$ is the probability that action $a$ in state $s$ at time $t$ will lead to state $s’$ at time $t+1$. </p>
</li>
<li><p>$\gamma\in[0,1]$ is a discount factor, which represents the difference in importance between future rewards and present rewards.</p>
</li>
</ul>
<p>The solution to the MDP is the policy $\pi(s)\rightarrow a$, which maximizes the long-term expected reward. In reinforcement learning domains, we simply assume the policy is deterministic and history-independent.</p>
<h1 id="Total-Reward"><a href="#Total-Reward" class="headerlink" title="Total Reward"></a>Total Reward</h1><p>$V(s)$, the state value function, is the total discounted reward from time-step $t$,</p>
<script type="math/tex; mode=display">\begin{align*}V(s_t)&=R(s_t)+\gamma R(s_{t+1})+\cdots\\
\qquad\qquad&=\sum\limits_{i=t}^{\infty}\gamma^iR(s_{i})\qquad 0\leqslant\gamma\leqslant 1
\end{align*}</script><p>We can show that </p>
<script type="math/tex; mode=display">V<\infty</script><h1 id="Policies"><a href="#Policies" class="headerlink" title="Policies"></a>Policies</h1><script type="math/tex; mode=display">\begin{align*}\pi^*&=\mathop{\arg\max}_{\pi}\mathbb{E}V^{\pi}\\
&=\mathop{\arg\max}_{a}\sum\limits_{s'\in S}P_a(s,s')V(s')
\end{align*}</script><p>The long term and delayed reward is given by</p>
<script type="math/tex; mode=display">V^{\pi}(s)=\mathbb{E}[V(s_0)|\pi,s_0=s]</script><p>which is not equal to the immediate reward $R(s)$.</p>
<p>From <strong>Bellman Equation</strong>, the value function can be decomposed into two parts:immediate reward $R(s)$ and discounted value of successor state $\gamma V(S_{t+1})$.</p>
<script type="math/tex; mode=display">\begin{align*}
V(s) &=\mathbb{E}[V|S_t=s]\\
&=\mathbb{E}\left[\sum\limits_{i=0}^{\infty}\gamma^iR_{i}|S_t=s\right]\\
&=\mathbb{E}[R(s)+V(s)|S_t=s]\\
&=\mathbb{E}[R(s)+\gamma V(S_{t+1})|S_t=s]\\
&= R(s)+ \gamma\sum\limits_{s'\in S}P_a(s,s')V(s')
\end{align*}</script><p>Similar result holds for $V^{\pi}(s)$.</p>
<h1 id="Policy-Iterated-RL"><a href="#Policy-Iterated-RL" class="headerlink" title="Policy-Iterated RL"></a>Policy-Iterated RL</h1><p>Policy iteration tries to evaluate and improve the policy in turn. Once a policy $\pi$ has been improved by using $V^{\pi}$ to yield a better policy $\pi’$, we can then compute $V^{\pi’}$ and improve it again to yield an even better policy. We can thus obtain a sequence of monotonically improving policies and value functions: <script type="math/tex">\pi_0\xrightarrow{E}V^{\pi_0}\xrightarrow{I}\pi_1\xrightarrow{E}\cdots \xrightarrow{I}V^{\pi^{\ast}}\xrightarrow{E}V^{\ast}</script><br>where $\xrightarrow{E}$ denotes a policy evaluation and $\xrightarrow{I}$ denotes a policy improvement. Each policy is guaranteed to be a strict improvement over the previous one (unless it is already optimal). Because a finite MDP has only a finite number of policies, this process must converge to an optimal policy and optimal value function in a finite number of iterations.</p>
<img src="/en/reinforcement-learning/MDP/MDP_algo_1.png" title="Policy Iteration">
<h1 id="Value-Iterated-RL"><a href="#Value-Iterated-RL" class="headerlink" title="Value-Iterated RL"></a>Value-Iterated RL</h1><p>One drawback to policy iteration is that each of its iterations involves policy evaluation, which may itself be a protracted iterative computation requiring multiple sweeps through the state set. If policy evaluation is done iteratively, then convergence exactly to  occurs only in the limit. </p>
<p>In fact, the policy evaluation step of policy iteration can be truncated in several ways without losing the convergence guarantees of policy iteration. One important special case is when policy evaluation is stopped after just one sweep (one backup of each state). This algorithm is called value iteration. It can be written as a particularly simple backup operation that combines the policy improvement and truncated policy evaluation steps: </p>
<script type="math/tex; mode=display">\begin{align*}V_{k+1}(s)&=\max\limits_a \mathbb{E}[ r_{t+1}+\gamma V_k(s_{t+1})]|s_t=s, a_t=a)\\
&=\max\limits_a \sum\limits_{s'} P_a(s,s')[ R_{a}(s,s')+\gamma V_k(s')] \end{align*}</script><p>for all $s\in S$. For arbitrary $V_0$, the sequence $\{V_k\}$ can be shown to converge to $V^\ast$ under the $V^\ast$.</p>
<img src="/en/reinforcement-learning/MDP/MDP_algo_2.png" title="Value Iteration">
<h1 id="Code-Example"><a href="#Code-Example" class="headerlink" title="Code Example"></a>Code Example</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"><span class="keyword">from</span> gym <span class="keyword">import</span> wrappers</span><br></pre></td></tr></table></figure>
<h2 id="Policy-Iterated-RL-1"><a href="#Policy-Iterated-RL-1" class="headerlink" title="Policy-Iterated RL"></a>Policy-Iterated RL</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_evaluation</span><span class="params">(env, policy, gamma=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Iteratively evaluate the value-function under policy.</span></span><br><span class="line"><span class="string">    Alternatively, we could formulate a set of linear equations in iterms of v[s] </span></span><br><span class="line"><span class="string">    and solve them to find the value function.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    v = np.zeros(env.nS)</span><br><span class="line">    eps = <span class="number">1e-10</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        prev_v = np.copy(v)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> range(env.nS):</span><br><span class="line">            policy_a = policy[s]</span><br><span class="line">            v[s] = sum([p * (r + gamma * prev_v[s_]) <span class="keyword">for</span> p, s_, r, _ <span class="keyword">in</span> env.P[s][policy_a]])</span><br><span class="line">        <span class="keyword">if</span> (np.sum((np.fabs(prev_v - v))) &lt;= eps):</span><br><span class="line">            <span class="comment"># value converged</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> v</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_improvement</span><span class="params">(v, gamma = <span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Extract the policy given a value-function """</span></span><br><span class="line">    policy = np.zeros(env.nS)</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> range(env.nS):</span><br><span class="line">        q_sa = np.zeros(env.nA)</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> range(env.nA):</span><br><span class="line">            q_sa[a] = sum([p * (r + gamma * v[s_]) <span class="keyword">for</span> p, s_, r, _ <span class="keyword">in</span>  env.P[s][a]])</span><br><span class="line">        policy[s] = np.argmax(q_sa)</span><br><span class="line">    <span class="keyword">return</span> policy</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_iteration</span><span class="params">(env, gamma = <span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Policy-Iteration algorithm """</span></span><br><span class="line">    <span class="comment"># initialize a random policy</span></span><br><span class="line">    policy = np.random.choice(env.nA, size=(env.nS))</span><br><span class="line">    <span class="comment"># parameter</span></span><br><span class="line">    max_iterations = <span class="number">200000</span></span><br><span class="line">    gamma = <span class="number">1.0</span></span><br><span class="line">    <span class="comment"># run iterations</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_iterations):</span><br><span class="line">        <span class="comment"># calculate the value given the old policy</span></span><br><span class="line">        old_policy_v = policy_evaluation(env, policy, gamma)</span><br><span class="line">        <span class="comment"># find the new policy</span></span><br><span class="line">        new_policy = policy_improvement(old_policy_v, gamma)</span><br><span class="line">        <span class="keyword">if</span> (np.all(policy == new_policy)):</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">'Policy-Iteration converged at step %d.'</span> %(i+<span class="number">1</span>))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        policy = new_policy</span><br><span class="line">    <span class="keyword">return</span> policy</span><br></pre></td></tr></table></figure>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_episode</span><span class="params">(env, policy, gamma = <span class="number">1.0</span>, render = False)</span>:</span></span><br><span class="line">    <span class="string">""" Runs an episode and return the total reward """</span></span><br><span class="line">    obs = env.reset()</span><br><span class="line">    total_reward = <span class="number">0</span></span><br><span class="line">    step_idx = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">if</span> render:</span><br><span class="line">            env.render()</span><br><span class="line">        obs, reward, done , _ = env.step(int(policy[obs]))</span><br><span class="line">        total_reward += (gamma ** step_idx * reward)</span><br><span class="line">        step_idx += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> total_reward</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_policy</span><span class="params">(env, policy, gamma = <span class="number">1.0</span>, n = <span class="number">100</span>, render = False)</span>:</span></span><br><span class="line">    scores = [run_episode(env, policy, gamma, render) <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)]</span><br><span class="line">    <span class="keyword">return</span> np.mean(scores)</span><br><span class="line"></span><br><span class="line">env_name  = <span class="string">'FrozenLake8x8-v0'</span></span><br><span class="line">env = gym.make(env_name).unwrapped</span><br><span class="line">optimal_policy = policy_iteration(env, gamma = <span class="number">1.0</span>)</span><br><span class="line">scores = evaluate_policy(env, optimal_policy, gamma = <span class="number">1.0</span>, render = <span class="literal">False</span>)</span><br><span class="line">print(<span class="string">'Average scores = '</span>, np.mean(scores))</span><br><span class="line"><span class="comment"># Policy-Iteration converged at step 13.</span></span><br><span class="line"><span class="comment"># Average scores =  1.0</span></span><br></pre></td></tr></table></figure>
<h2 id="Value-Iterated-RL-1"><a href="#Value-Iterated-RL-1" class="headerlink" title="Value-Iterated RL"></a>Value-Iterated RL</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_policy</span><span class="params">(v, gamma = <span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Extract the policy given a value-function """</span></span><br><span class="line">    policy = np.zeros(env.nS)</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> range(env.nS):</span><br><span class="line">        q_sa = np.zeros(env.action_space.n)</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> range(env.action_space.n):</span><br><span class="line">            <span class="keyword">for</span> next_sr <span class="keyword">in</span> env.P[s][a]:</span><br><span class="line">                <span class="comment"># next_sr is a tuple of (probability, next state, reward, done)</span></span><br><span class="line">                p, s_, r, _ = next_sr</span><br><span class="line">                q_sa[a] += (p * (r + gamma * v[s_]))</span><br><span class="line">        policy[s] = np.argmax(q_sa)</span><br><span class="line">    <span class="keyword">return</span> policy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">value_iteration</span><span class="params">(env, gamma = <span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Value-iteration algorithm """</span></span><br><span class="line">    v = np.zeros(env.nS)  <span class="comment"># initialize value-function</span></span><br><span class="line">    max_iterations = <span class="number">100000</span></span><br><span class="line">    eps = <span class="number">1e-20</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_iterations):</span><br><span class="line">        prev_v = np.copy(v)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> range(env.nS):</span><br><span class="line">            q_sa = [sum([p*(r + prev_v[s_]) <span class="keyword">for</span> p, s_, r, _ <span class="keyword">in</span> env.P[s][a]]) <span class="keyword">for</span> a <span class="keyword">in</span> range(env.nA)]</span><br><span class="line">            v[s] = max(q_sa)</span><br><span class="line">        <span class="keyword">if</span> (np.sum(np.fabs(prev_v - v)) &lt;= eps):</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">'Value-iteration converged at iteration# %d.'</span> %(i+<span class="number">1</span>))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure>
<h2 id="Evaluation-1"><a href="#Evaluation-1" class="headerlink" title="Evaluation"></a>Evaluation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_episode</span><span class="params">(env, policy, gamma = <span class="number">1.0</span>, render = False)</span>:</span></span><br><span class="line">    <span class="string">""" Evaluates policy by using it to run an episode and finding its</span></span><br><span class="line"><span class="string">    total reward.</span></span><br><span class="line"><span class="string">    args:</span></span><br><span class="line"><span class="string">    env: gym environment.</span></span><br><span class="line"><span class="string">    policy: the policy to be used.</span></span><br><span class="line"><span class="string">    gamma: discount factor.</span></span><br><span class="line"><span class="string">    render: boolean to turn rendering on/off.</span></span><br><span class="line"><span class="string">    returns:</span></span><br><span class="line"><span class="string">    total reward: real value of the total reward recieved by agent under policy.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    obs = env.reset()</span><br><span class="line">    total_reward = <span class="number">0</span></span><br><span class="line">    step_idx = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">if</span> render:</span><br><span class="line">            env.render()</span><br><span class="line">        obs, reward, done , _ = env.step(int(policy[obs]))</span><br><span class="line">        total_reward += (gamma ** step_idx * reward)</span><br><span class="line">        step_idx += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> total_reward</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_policy</span><span class="params">(env, policy, gamma = <span class="number">1.0</span>,  n = <span class="number">100</span>)</span>:</span></span><br><span class="line">    <span class="string">""" Evaluates a policy by running it n times.</span></span><br><span class="line"><span class="string">    returns:</span></span><br><span class="line"><span class="string">    average total reward</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    scores = [</span><br><span class="line">            run_episode(env, policy, gamma = gamma, render = <span class="literal">False</span>)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> range(n)]</span><br><span class="line">    <span class="keyword">return</span> np.mean(scores)</span><br><span class="line"></span><br><span class="line">env_name  = <span class="string">'FrozenLake8x8-v0'</span></span><br><span class="line">gamma = <span class="number">1.0</span></span><br><span class="line">env = gym.make(env_name).unwrapped</span><br><span class="line">optimal_v = value_iteration(env, gamma);</span><br><span class="line">policy = extract_policy(optimal_v, gamma)</span><br><span class="line">policy_score = evaluate_policy(env, policy, gamma, n=<span class="number">1000</span>)</span><br><span class="line">print(<span class="string">'Policy average score = '</span>, policy_score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Value-iteration converged at iteration# 2357.</span></span><br><span class="line"><span class="comment"># Policy average score =  1.0</span></span><br></pre></td></tr></table></figure>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><a href="http://incompleteideas.net/book/first/ebook/node43.html" target="_blank" rel="noopener">Policy Iteration</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/reinforcement-learning/Q-learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/reinforcement-learning/Q-learning/" itemprop="url">Q-learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-27T10:51:23-05:00">
                2019-04-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/reinforcement-learning/" itemprop="url" rel="index">
                    <span itemprop="name">reinforcement-learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/reinforcement-learning/Q-learning/" class="leancloud_visitors" data-flag-title="Q-learning">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Q-leaning is a model-free (no need to build a model of environment) reinforcement learning method. The goal of Q-leaning is to learn a policy, which can be used to guide a agent to take corresponding action in different states. For any finite Markov Decision Process, Q-learning can find the optimal policy that miximizes the expected total reward.</p>
<h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><p>Reinforcement learning includes a agent, a state set $S$ and an action set $A$. When the state $s_t\in S$ is observed, the agent will choose an action $a_t\in A$. Then it will get a reward $r_t$ and goes to the next state $s_{t+1}$.</p>
<p>Our goal is to maximize the future total reward, i.e., the expection of total reward given the current state. In practice, we usually use weighted sum, e.g., discount criterion to compute the expected total reward.</p>
<p>Q-learning is used to learn a function $Q:S\times A\mapsto \mathbb{R}$. At any state $s_t$, the agent can choose an action $a_t$ such that $Q(s_t,a_t)$ is maximized。</p>
<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h1><p>To use Q-learning, wehave to find a way to learn the $Q$ function. The simplest way is to maintain a table with size $|S|\times |A|$, and use value iteration to update the Q-table. The update rule is given by</p>
<script type="math/tex; mode=display">Q^{new}(s_{t},a_{t})\leftarrow (1-\alpha )\cdot  Q(s_{t},a_{t})+\alpha \cdot  \left( r_t + \gamma \cdot \max_a Q(s_{t+1},a) \right)</script><p>whick requires $s_t$, $r_t$ and $s_{t+1}$ at each update step.</p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="comment"># 1. Load Environment and Q-table structure</span></span><br><span class="line">env = gym.make(<span class="string">'FrozenLake8x8-v0'</span>)</span><br><span class="line">Q = np.zeros([env.observation_space.n,env.action_space.n])</span><br><span class="line"><span class="comment"># env.obeservation.n, env.action_space.n gives number of states and action in env loaded</span></span><br><span class="line">	</span><br><span class="line"><span class="comment"># 2. Parameters of Q-leanring</span></span><br><span class="line">eta = <span class="number">.628</span></span><br><span class="line">gma = <span class="number">.9</span></span><br><span class="line">epis = <span class="number">100</span></span><br><span class="line">rev_list = [] <span class="comment"># reward per episode calculate</span></span><br><span class="line">	</span><br><span class="line"><span class="comment"># 3. Q-learning Algorithm</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(epis):</span><br><span class="line">    <span class="comment"># Reset environment</span></span><br><span class="line">    s = env.reset()</span><br><span class="line">    rAll = <span class="number">0</span></span><br><span class="line">    d = <span class="literal">False</span></span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># The Q-Table learning algorithm</span></span><br><span class="line">    <span class="keyword">while</span> j &lt; <span class="number">99</span>:</span><br><span class="line">        env.render()</span><br><span class="line">        j+=<span class="number">1</span></span><br><span class="line">        <span class="comment"># Choose action from Q table</span></span><br><span class="line">        a = np.argmax(Q[s,:] + np.random.randn(<span class="number">1</span>,env.action_space.n)*(<span class="number">1.</span>/(i+<span class="number">1</span>)))</span><br><span class="line">        <span class="comment"># Get new state &amp; reward from environment</span></span><br><span class="line">        s1,r,d,_ = env.step(a)</span><br><span class="line">        <span class="comment"># Update Q-Table with new knowledge</span></span><br><span class="line">        Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])</span><br><span class="line">        rAll += r</span><br><span class="line">        s = s1</span><br><span class="line">        <span class="keyword">if</span> d == <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    rev_list.append(rAll)</span><br><span class="line">    env.render()</span><br></pre></td></tr></table></figure>
<h2 id="Variants"><a href="#Variants" class="headerlink" title="Variants"></a>Variants</h2><ol>
<li>Deep Q-learning</li>
<li>Double Q-learning</li>
<li>Double Deep Q-learning</li>
<li>Delayed Q-learning</li>
<li>Greedly GQ</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/course/UChicago/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/course/UChicago/" itemprop="url">Course materials in UChicago</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-25T19:40:52-05:00">
                2019-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/course/" itemprop="url" rel="index">
                    <span itemprop="name">course</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/course/UChicago/" class="leancloud_visitors" data-flag-title="Course materials in UChicago">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Course Name</th>
<th>Github</th>
<th>BaiduDisk </th>
</tr>
</thead>
<tbody>
<tr>
<td>STAT30400 - Distribution Theory</td>
<td><a href="https://github.com/jaydu1/Course-Material/tree/master/UChicago/Statistics/STAT%2030400%20-%20Distribution%20Theory" target="_blank" rel="noopener">link</a></td>
<td><a href="https://pan.baidu.com/s/1Tmy8WUMuAtyS3_wNqYP46Q" target="_blank" rel="noopener">de7j</a></td>
</tr>
<tr>
<td>STAT30900 - Mathematical Computation I:Matrix Computation</td>
<td><a href="https://github.com/jaydu1/Course-Material/tree/master/UChicago/Statistics/STAT%2030900%20-%20Mathematical%20Computation%20I-Matrix%20Computation" target="_blank" rel="noopener">link</a></td>
<td><a href="https://pan.baidu.com/s/1bbsUVcX4_pJr8ir7I4XA3g" target="_blank" rel="noopener">cq9v</a></td>
</tr>
<tr>
<td>STAT34300 - Applied Linear Statistical Model</td>
<td><a href="https://github.com/jaydu1/Course-Material/tree/master/UChicago/Statistics/STAT%2034300%20-%20Applied%20Linear%20Statistical%20Model" target="_blank" rel="noopener">link</a></td>
<td><a href="https://pan.baidu.com/s/1p1IVliUYyCf2vtgBMOegNQ" target="_blank" rel="noopener">y79v</a></td>
</tr>
</tbody>
</table>
</div>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
                  
        

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/en/course/UCB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jinhong Du">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/en/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jaydu1">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/en/course/UCB/" itemprop="url">Course materials in UCB</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-25T19:40:52-05:00">
                2019-04-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/en/categories/course/" itemprop="url" rel="index">
                    <span itemprop="name">course</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/en/course/UCB/" class="leancloud_visitors" data-flag-title="Course materials in UCB">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Math"><a href="#Math" class="headerlink" title="Math"></a>Math</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Course Name</th>
<th>Github</th>
<th>BaiduDisk </th>
</tr>
</thead>
<tbody>
<tr>
<td>MATH 118 - Fourier Analysis and Wavelets</td>
<td><a href="https://github.com/jaydu1/Course-Material/tree/master/UCB/Math/MATH%20118%20-%20Fourier%20Analysis%20and%20Wavelets" target="_blank" rel="noopener">link</a></td>
<td><a href="https://pan.baidu.com/s/1l6xyYaTNdwFcpPknA83U8A" target="_blank" rel="noopener">2xx9</a></td>
</tr>
</tbody>
</table>
</div>
<h2 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Course Name</th>
<th>Github</th>
<th>BaiduDisk </th>
</tr>
</thead>
<tbody>
<tr>
<td>STAT150 - Stochastic Processes</td>
<td><a href="https://github.com/jaydu1/Course-Material/tree/master/UCB/Statistics/STAT150%20-%20Stochastic%20Processes" target="_blank" rel="noopener">link</a></td>
<td><a href="https://pan.baidu.com/s/1GeGEzIt5OqPUDSd-DRmImg" target="_blank" rel="noopener">bsx2</a></td>
</tr>
</tbody>
</table>
</div>
<h2 id="Computer-Science"><a href="#Computer-Science" class="headerlink" title="Computer Science"></a>Computer Science</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Course Name</th>
<th>Github</th>
<th>BaiduDisk </th>
</tr>
</thead>
<tbody>
<tr>
<td>CS189 - Machine Learning</td>
<td><a href="https://github.com/jaydu1/Course-Material/tree/master/UCB/Computer%20Science/CS189%20-%20Machine%20Learning" target="_blank" rel="noopener">link</a></td>
<td><a href="https://pan.baidu.com/s/1pxQKfwChBQZHlQXgIWV11w" target="_blank" rel="noopener">yoqg</a></td>
</tr>
</tbody>
</table>
</div>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


       
    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/en/page/2/">2</a><a class="extend next" rel="next" href="/en/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/en/images/avatar.png" alt="Jinhong Du">
            
              <p class="site-author-name" itemprop="name">Jinhong Du</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/en/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/en/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/en/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jaydu1" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jayduking@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jinhong Du</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/en/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/en/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/en/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/en/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/en/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/en/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/en/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/en/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/en/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/en/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/en/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("5aOOwIWB3aC4iaRjNDJrYJgm-gzGzoHsz", "Vm6WEpC1PP66yMVQ3QGXrign");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
